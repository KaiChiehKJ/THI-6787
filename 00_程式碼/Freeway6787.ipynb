{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcccf2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import subprocess\n",
    "import shutil\n",
    "import tarfile\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "def create_folder(folder_name):\n",
    "    \"\"\"建立資料夾\"\"\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    return os.path.abspath(folder_name)\n",
    "\n",
    "def delete_folders(deletelist):\n",
    "    \"\"\"\n",
    "    刪除資料夾\n",
    "    deletelist(list):需要為皆為路徑的list\n",
    "    \"\"\"\n",
    "    for folder_name in deletelist: \n",
    "        if os.path.exists(folder_name): # 檢查資料夾是否存在\n",
    "            shutil.rmtree(folder_name) # 刪除資料夾及其內容\n",
    "        else:\n",
    "            print(f\"資料夾 '{folder_name}' 不存在。\")\n",
    "\n",
    "def getdatelist(time1, time2):\n",
    "    '''\n",
    "    建立日期清單\n",
    "    time1、time2(str):為%Y-%M-%D格式的日期字串\n",
    "    '''\n",
    "    if time1 > time2:\n",
    "        starttime = time2\n",
    "        endtime = time1\n",
    "    else:\n",
    "        starttime = time1\n",
    "        endtime = time2\n",
    "\n",
    "    date_range = pd.date_range(start=starttime, end=endtime)\n",
    "    datelist = [d.strftime(\"%Y%m%d\") for d in date_range]\n",
    "    return datelist\n",
    "\n",
    "def freewaydatafolder(datatype):\n",
    "    # savelocation = create_folder(os.path.join(os.getcwd(),'..','Output', datatype))\n",
    "    savelocation = create_folder(os.path.join(os.getcwd(),'..','01_資料初步彙整','03_高公局資料', datatype))\n",
    "    rawdatafolder = create_folder(os.path.join(savelocation, '0_rawdata'))\n",
    "    mergefolder = create_folder(os.path.join(savelocation, '1_merge'))\n",
    "    excelfolder = create_folder(os.path.join(savelocation, '2_excel'))\n",
    "    return rawdatafolder, mergefolder, excelfolder\n",
    "\n",
    "def delete_folders_permanently(deletelist):\n",
    "    \"\"\"\n",
    "    永久刪除資料夾及其內容，不放入資源回收筒\n",
    "    deletelist (list): 需要刪除的資料夾路徑列表\n",
    "    \"\"\"\n",
    "    for item in deletelist:\n",
    "        if os.path.isdir(item):  # 檢查是否為資料夾\n",
    "            try:\n",
    "                shutil.rmtree(item)  # 永久刪除資料夾\n",
    "                print(f\"已永久刪除資料夾： {item}\")\n",
    "            except OSError as e:\n",
    "                print(f\"刪除資料夾 {item} 時發生錯誤： {e}\")\n",
    "        elif os.path.isfile(item):  # 檢查是否為檔案\n",
    "            try:\n",
    "                os.remove(item)  # 永久刪除檔案\n",
    "                print(f\"已永久刪除檔案： {item}\")\n",
    "            except OSError as e:\n",
    "                print(f\"刪除檔案 {item} 時發生錯誤： {e}\")\n",
    "        else:\n",
    "            print(f\"{item} 不是檔案或資料夾。\")\n",
    "\n",
    "def download_etag(etagurl, etagdownloadpath):\n",
    "    \"\"\"\n",
    "    下載指定網址的 XML 檔案到指定位置。\n",
    "\n",
    "    Args:\n",
    "        etagurl (str): 要下載的 XML 檔案網址。\n",
    "        etagdownloadpath (str): 檔案下載後的儲存路徑（包含檔案名稱）。\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(etagurl, stream=True)\n",
    "        response.raise_for_status()  # 檢查 HTTP 狀態碼，如有錯誤則拋出異常\n",
    "\n",
    "        with open(etagdownloadpath, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"下載時發生錯誤：{e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"發生錯誤：{e}\")\n",
    "\n",
    "def read_xml(xml_file_path):\n",
    "    \"\"\"\n",
    "    讀取並解析 XML 檔案。\n",
    "\n",
    "    Args:\n",
    "        xml_file_path (str): XML 檔案路徑。\n",
    "\n",
    "    Returns:\n",
    "        ElementTree.Element: XML 文件的根節點。\n",
    "        None: 如果解析失敗。\n",
    "    \"\"\"\n",
    "    # try:\n",
    "    #     tree = ET.parse(xml_file_path)\n",
    "    #     root = tree.getroot()\n",
    "    #     return root\n",
    "    try:\n",
    "        with open(xml_file_path, 'r', encoding='utf-8') as f:  # 指定編碼\n",
    "            xml_content = f.read()\n",
    "        return xml_content\n",
    "    except FileNotFoundError:\n",
    "        print(f\"檔案未找到：{xml_file_path}\")\n",
    "        return None\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"解析 XML 檔案時發生錯誤：{e}\")\n",
    "        return None\n",
    "\n",
    "def etag_xml_to_dataframe(xml_content):\n",
    "    \"\"\"\n",
    "    將 XML 內容轉換為 Pandas DataFrame。\n",
    "\n",
    "    Args:\n",
    "        xml_content (str): XML 內容字串。\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 轉換後的 DataFrame。\n",
    "        None: 如果解析失敗。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        root = ET.fromstring(xml_content)  # 從字串解析 XML\n",
    "\n",
    "        data = []\n",
    "        for etag in root.findall('.//{http://traffic.transportdata.tw/standard/traffic/schema/}ETag'):\n",
    "            etag_data = {}\n",
    "            for element in etag:\n",
    "                tag_name = element.tag.split('}')[-1]  # 去除命名空間\n",
    "                if tag_name == 'RoadSection':  # 處理 RoadSection\n",
    "                    for section_element in element:\n",
    "                        etag_data[section_element.tag] = section_element.text\n",
    "                else:\n",
    "                    etag_data[tag_name] = element.text\n",
    "            data.append(etag_data)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df.columns = ['ETagGantryID','LinkID', 'LocationType', 'PositionLon', 'PositionLat', 'RoadID', 'RoadName', 'RoadClass', 'RoadDirection', 'Start','End', 'LocationMile']\n",
    "        return df\n",
    "\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"解析 XML 內容時發生錯誤：{e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"發生錯誤：{e}\")\n",
    "        return None\n",
    "\n",
    "def etag_getdf():\n",
    "    etagfolder = create_folder(os.path.join(os.getcwd(),'..','01_資料初步彙整','03_高公局資料', 'ETag'))\n",
    "    etagurl = 'https://tisvcloud.freeway.gov.tw/history/motc20/ETag.xml'\n",
    "    etagdownloadpath = os.path.join(etagfolder, 'ETag.xml')\n",
    "    download_etag(etagurl=etagurl, etagdownloadpath=etagdownloadpath)\n",
    "    etagxml = read_xml(etagdownloadpath)\n",
    "    etag = etag_xml_to_dataframe(etagxml)\n",
    "\n",
    "    etag.to_excel(os.path.join(etagfolder,'Etag.xlsx'), index = False, sheet_name='ETag')\n",
    "    return etag\n",
    "\n",
    "def extract_tar_gz(tar_gz_file, extract_path):\n",
    "    try:\n",
    "        with tarfile.open(tar_gz_file, 'r:gz') as tar:\n",
    "            tar.extractall(path=extract_path)\n",
    "    except Exception as e:\n",
    "        print(f\"解壓縮 {tar_gz_file} 失敗：{e}\")\n",
    "\n",
    "def download_and_extract(url, datatype, date, downloadfolder, keep = False):\n",
    "    '''針對高公局交通資料庫的格式進行下載'''\n",
    "    downloadurl = f\"{url}/{datatype}_{date}.tar.gz\"\n",
    "    destfile = os.path.join(downloadfolder, f\"{datatype}_{date}.tar.gz\")\n",
    "\n",
    "    response = requests.get(downloadurl)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(destfile, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        extractpath = create_folder(os.path.join(downloadfolder, date))\n",
    "        extract_tar_gz(destfile, extractpath)\n",
    "        if keep == False:\n",
    "            os.remove(destfile)\n",
    "    else:\n",
    "        extractpath = create_folder(os.path.join(downloadfolder, date))\n",
    "        hourlist = [f\"{i:02d}\" for i in range(24)]\n",
    "        if datatype == 'M06A':\n",
    "            for hour in hourlist:\n",
    "                downloadurl = f\"{url}/{date}/{hour}/TDCS_{datatype}_{date}_{hour}0000.csv\"\n",
    "                destfile = os.path.join(extractpath, f\"TDCS_{datatype}_{date}_{hour}0000.csv\")\n",
    "                response = requests.get(downloadurl, stream=True) # 發送 GET 請求下載檔案\n",
    "                if response.status_code == 200:\n",
    "                    with open(destfile, 'wb') as file:\n",
    "                        file.write(response.content)  # 直接寫入整個回應內容\n",
    "                else:\n",
    "                    print(f\"下載失敗: {downloadurl}, 狀態碼: {response.status_code}\")\n",
    "\n",
    "        else :\n",
    "            for hour in hourlist:\n",
    "                minlist = [f\"{i:02d}\" for i in range(0, 60, 5)]\n",
    "                for minute in minlist:\n",
    "                    downloadurl = f\"{url}/{date}/{hour}/TDCS_{datatype}_{date}_{hour}{minute}00.csv\"\n",
    "                    destfile = os.path.join(extractpath, f\"TDCS_{datatype}_{date}_{hour}{minute}00.csv\")\n",
    "\n",
    "                    response = requests.get(downloadurl, stream=True) # 發送 GET 請求下載檔案\n",
    "                    \n",
    "                    if response.status_code == 200:\n",
    "                        with open(destfile, 'wb') as file:\n",
    "                            file.write(response.content)  # 直接寫入整個回應內容\n",
    "                    else:\n",
    "                        print(f\"下載失敗: {downloadurl}, 狀態碼: {response.status_code}\")\n",
    "\n",
    "    return extractpath\n",
    "\n",
    "def findfiles(filefolderpath, filetype='.csv'):\n",
    "    \"\"\"\n",
    "    尋找指定路徑下指定類型的檔案，並返回檔案路徑列表。\n",
    "\n",
    "    Args:\n",
    "        filefolderpath (str): 指定的檔案路徑。\n",
    "        filetype (str, optional): 要尋找的檔案類型，預設為 '.csv'。\n",
    "\n",
    "    Returns:\n",
    "        list: 包含所有符合條件的檔案路徑的列表。\n",
    "    \"\"\"\n",
    "\n",
    "    filelist = []  # 建立一個空列表來儲存檔案路徑\n",
    "\n",
    "    # 使用 os.walk 遍歷資料夾及其子資料夾\n",
    "    for root, _, files in os.walk(filefolderpath):\n",
    "        for file in files:\n",
    "            if file.endswith(filetype):  # 檢查檔案是否以指定類型結尾\n",
    "                file_path = os.path.join(root, file)  # 建立完整的檔案路徑\n",
    "                filelist.append(file_path)  # 將檔案路徑添加到列表中\n",
    "\n",
    "    return filelist\n",
    "\n",
    "def combinefile(filelist, datatype='M03A'):\n",
    "    \"\"\"\n",
    "    更有效率地合併多個CSV檔案。\n",
    "\n",
    "    Args:\n",
    "        filelist (list): 包含CSV檔案路徑的列表。\n",
    "        datatype (str, optional): 資料類型，決定欄位名稱。預設為 'M03A'。\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: 合併後的DataFrame。\n",
    "    \"\"\"\n",
    "\n",
    "    # 使用字典來映射資料類型和欄位名稱，避免重複的 if/elif 判斷\n",
    "    column_mapping = {\n",
    "        'M03A': ['TimeStamp', 'GantryID', 'Direction', 'VehicleType', 'Volume'],\n",
    "        'M04A': ['TimeStamp', 'GantryFrom', 'GantryTo', 'VehicleType', 'TravelTime', 'Volume'],\n",
    "        'M05A': ['TimeStamp', 'GantryFrom', 'GantryTo', 'VehicleType', 'Speed', 'Volume'],\n",
    "        'M06A': ['VehicleType', 'DetectionTimeO', 'GantryO', 'DetectionTimeD', 'GantryD', 'TripLength', 'TripEnd', 'TripInformation'],\n",
    "        'M07A': ['TimeStamp', 'GantryO', 'VehicleType', 'AverageTripLength', 'Volume'],\n",
    "        'M08A': ['TimeStamp', 'GantryO', 'GantryD', 'VehicleType', 'Trips']\n",
    "    }\n",
    "\n",
    "    columns = column_mapping.get(datatype)  # 使用 get() 方法，如果找不到鍵，會返回 None\n",
    "    if columns is None:\n",
    "        raise ValueError(f\"未知的資料類型：{datatype}\")\n",
    "\n",
    "    combineddf = pd.concat(\n",
    "        (pd.read_csv(i, header=None, names=columns) for i in filelist),  # 使用生成器表達式\n",
    "        ignore_index=True  # 避免重複的索引\n",
    "    )\n",
    "\n",
    "    return combineddf\n",
    "\n",
    "def THI_M03A(df):\n",
    "    df = df.pivot(index=['TimeStamp', 'GantryID', 'Direction'], columns='VehicleType', values='Volume').reset_index()\n",
    "    df = df.rename(columns = {\n",
    "        5 : 'Vol_Trail',\n",
    "        31 : 'Vol_Car',\n",
    "        32 : 'Vol_Truck',\n",
    "        41 : 'Vol_TourBus',\n",
    "        42 : 'Vol_BTruck'\n",
    "    })\n",
    "    df = df.reindex(columns = ['TimeStamp', 'GantryID', 'Direction', 'Vol_Trail', 'Vol_Car', 'Vol_Truck', 'Vol_TourBus', 'Vol_BTruck'])\n",
    "\n",
    "    df['TimeStamp'] = pd.to_datetime(df['TimeStamp'])\n",
    "\n",
    "    df['Date'] = df['TimeStamp'].dt.date\n",
    "    df['Hour'] = df['TimeStamp'].dt.hour\n",
    "\n",
    "    df = df.groupby(['Date','Hour','GantryID','Direction']).agg({\n",
    "            'Vol_Trail':'sum',\n",
    "            'Vol_Car':'sum', \n",
    "            'Vol_Truck':'sum',\n",
    "            'Vol_TourBus':'sum',\n",
    "            'Vol_BTruck':'sum'}).reset_index()\n",
    "    return df\n",
    "\n",
    "# def THI_M05A(df, weighted = False):\n",
    "    \n",
    "#     # 將每5分鐘的資料，轉為分時資料\n",
    "#     df['TimeStamp'] = pd.to_datetime(df['TimeStamp'])\n",
    "#     df['Date'] = df['TimeStamp'].dt.date\n",
    "#     df['Hour'] = df['TimeStamp'].dt.hour\n",
    "\n",
    "#     df = df[df['Volume']!=0] # 需要避開Volume 為0的資料\n",
    "\n",
    "#     if weighted == True:\n",
    "#         df['Speed_time_volume'] = df['Speed'] * df['Volume']\n",
    "#         df = df.groupby(['Date', 'Hour', 'GantryFrom', 'GantryTo', 'VehicleType']).agg({'Speed_time_volume':'sum', 'Volume':'sum'}).reset_index()\n",
    "#         df['Speed'] = df['Speed_time_volume'] / df['Volume']\n",
    "#     else :\n",
    "#         df = df.groupby(['Date', 'Hour', 'GantryFrom', 'GantryTo', 'VehicleType']).agg({'Speed':'mean'}).reset_index()\n",
    "    \n",
    "    \n",
    "#     df['Speed'] = df['Speed'].round(3)\n",
    "#     df = df.pivot(index=['Date', 'Hour', 'GantryFrom', 'GantryTo'], columns='VehicleType', values='Speed').reset_index()\n",
    "#     df = df.rename(columns = {\n",
    "#         5 : 'Speed_Trail',\n",
    "#         31 : 'Speed_Car',\n",
    "#         32 : 'Speed_Truck',\n",
    "#         41 : 'Speed_TourBus',\n",
    "#         42 : 'Speed_BTruck'\n",
    "#     })\n",
    "\n",
    "#     df = df.fillna(0)\n",
    "#     df = df.reindex(columns = ['Date', 'Hour', 'GantryFrom', 'GantryTo', 'Speed_Trail', 'Speed_Car', 'Speed_Truck', 'Speed_TourBus', 'Speed_BTruck'])\n",
    "    \n",
    "#     return df\n",
    "\n",
    "\n",
    "def THI_M05A(df, weighted = False):\n",
    "    \n",
    "    # 將每5分鐘的資料，轉為分時資料\n",
    "    df['TimeStamp'] = pd.to_datetime(df['TimeStamp'])\n",
    "    df['Date'] = df['TimeStamp'].dt.date\n",
    "    df['Hour'] = df['TimeStamp'].dt.hour\n",
    "\n",
    "    df = df[df['Volume']!=0] # 需要避開Volume 為0的資料\n",
    "\n",
    "    if weighted == True:\n",
    "        df['Speed_time_volume'] = df['Speed'] * df['Volume']\n",
    "        df = df.groupby(['Date', 'Hour', 'GantryFrom', 'GantryTo', 'VehicleType']).agg({'Speed_time_volume':'sum', 'Volume':'sum'}).reset_index()\n",
    "        df['Speed'] = df['Speed_time_volume'] / df['Volume']\n",
    "    else :\n",
    "        df = df.groupby(['Date', 'Hour', 'GantryFrom', 'GantryTo', 'VehicleType']).agg({'Speed':'mean'}).reset_index()\n",
    "    \n",
    "    \n",
    "    df['Speed'] = df['Speed'].round(3)\n",
    "    df = df.pivot(index=['Date', 'Hour', 'GantryFrom', 'GantryTo'], columns='VehicleType', values='Speed').reset_index()\n",
    "    df = df.rename(columns = {\n",
    "        5 : 'Speed_Trail',\n",
    "        31 : 'Speed_Car',\n",
    "        32 : 'Speed_Truck',\n",
    "        41 : 'Speed_TourBus',\n",
    "        42 : 'Speed_BTruck'\n",
    "    })\n",
    "\n",
    "    etag = pd.read_excel(os.path.join(os.getcwd(),'..','Input',\"靜態資料\", \"Table\", \"ETag整併資料.xlsx\"))\n",
    "    etag = etag.reindex(columns = ['ETagGantryID','UpstreamDistance','DownstreamDistance','SpeedLimit'])\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    df = df.reindex(columns = ['Date', 'Hour', 'GantryFrom', 'GantryTo', 'Speed_Trail', 'Speed_Car', 'Speed_Truck', 'Speed_TourBus', 'Speed_BTruck'])\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    df = df.reindex(columns = ['Date', 'Hour', 'GantryFrom', 'GantryTo', 'Speed_Trail', 'Speed_Car', 'Speed_Truck', 'Speed_TourBus', 'Speed_BTruck'])\n",
    "\n",
    "    df['Speed'] = df[['Speed_Trail', 'Speed_Car', 'Speed_Truck', 'Speed_TourBus', 'Speed_BTruck']].replace(0, np.nan).mean(axis=1, skipna=True)\n",
    "    df['Speed'] = df['Speed'].round(3)\n",
    "\n",
    "    M05A = pd.merge(etag, df[['Date', 'Hour', 'Speed', 'GantryTo']].rename(columns = {'Speed':'UpstreamSpeed', 'GantryTo':'ETagGantryID'}), on = 'ETagGantryID', how = 'left')\n",
    "    M05A = pd.merge(M05A, df[['Date', 'Hour', 'Speed', 'GantryFrom']].rename(columns = {'Speed':'DownstreamSpeed', 'GantryFrom':'ETagGantryID'}), on = ['Date', 'Hour', 'ETagGantryID'], how = 'left' )\n",
    "    M05A['UpstreamTime'] = M05A['UpstreamDistance'] / M05A['UpstreamSpeed']\n",
    "    M05A['DownstreamTime'] = M05A['DownstreamDistance'] / M05A['DownstreamSpeed']\n",
    "    M05A['Speed'] = (M05A['UpstreamDistance'] + M05A['DownstreamDistance']) / (M05A['UpstreamTime'] + M05A['DownstreamTime'])\n",
    "    M05A = M05A.reindex(columns = ['Date','Hour','ETagGantryID', 'Speed', 'SpeedLimit'])\n",
    "    M05A['Speed'] = M05A['Speed'].round(3)\n",
    "    \n",
    "    return M05A\n",
    "\n",
    "\n",
    "\n",
    "# def THI_M06A(df, hour = True):\n",
    "#     df['DetectionTimeO'] = pd.to_datetime(df['DetectionTimeO'])\n",
    "#     df['DetectionTimeD'] = pd.to_datetime(df['DetectionTimeD'])\n",
    "\n",
    "#     df['Date'] = df['DetectionTimeO'].dt.date\n",
    "#     if hour == True:\n",
    "#         df['HourO'] = df['DetectionTimeO'].dt.hour\n",
    "#         df['HourD'] = df['DetectionTimeD'].dt.hour\n",
    "#         df = df.groupby(['Date','HourO', 'GantryO', 'HourD', 'GantryD', 'VehicleType']).size().reset_index(name='Volume')\n",
    "\n",
    "#     df = df.groupby(['Date', 'GantryO', 'GantryD','VehicleType']).size().reset_index(name='Volume')\n",
    "\n",
    "#     return df \n",
    "\n",
    "def THI_M06A_step1(df):\n",
    "    '''把所有的M06A每一個路徑都拆分成每一筆M03A，並賦予他index編號'''\n",
    "    df = df.reset_index()\n",
    "    df[\"TripInformation\"] = df[\"TripInformation\"].str.split(\"; \")\n",
    "    # 2. 使用 explode 展開每一筆紀錄\n",
    "    df = df.explode(\"TripInformation\").reset_index(drop=True)\n",
    "    # 3. 拆分 DetectionTime 和 GantryID\n",
    "    df[[\"DetectionTime\", \"GantryID\"]] = df[\"TripInformation\"].str.split(\"+\", expand=True)\n",
    "    df[\"DetectionTime\"] = pd.to_datetime(df[\"DetectionTime\"])\n",
    "    df['DetectionDate'] = df[\"DetectionTime\"].dt.date\n",
    "    df['DetectionHour'] = df[\"DetectionTime\"].dt.hour\n",
    "    df = df.reindex(columns = ['index', 'VehicleType','DetectionDate','DetectionHour', 'GantryID'])\n",
    "    df_grouped = df.groupby(\"index\")[\"GantryID\"].apply(list).reset_index()\n",
    "    df = df.merge(df_grouped, on=\"index\", suffixes=(\"\", \"_list\"))\n",
    "    return df  \n",
    "\n",
    "def THI_M06A_step2(df, ramp):\n",
    "    '''ramp會是由你先前選擇的分析路口進行，需要人工進行挑選，目前尚無法自動化\n",
    "    df 為 THI_M06A_step1 處理玩的ETC資料\n",
    "    return 的 final_df 為各匝道進出的資料'''\n",
    "    # 初始化統計結果\n",
    "    results = []\n",
    "\n",
    "    # 遍歷 ramp 表，找符合條件的資料\n",
    "    for _, row in ramp.iterrows():\n",
    "        ramp_name, direction, pass_id, unpass_id = row\n",
    "\n",
    "        # 篩選有經過 PassGantryID 但沒有 UnpassGantryID 的車輛\n",
    "        matched_df = df[df[\"GantryID_list\"].apply(lambda x: pass_id in x and unpass_id not in x)]\n",
    "        matched_df = matched_df[matched_df['GantryID'] == pass_id]\n",
    "\n",
    "        # 統計不同 VehicleType 在各時段的數量\n",
    "        summary = matched_df.groupby([\"DetectionDate\",\"DetectionHour\", \"VehicleType\"])[\"index\"].nunique().reset_index(name=\"Count\")\n",
    "\n",
    "        # 加入 Ramp 和 Direction 資訊\n",
    "        summary[\"Ramp\"] = ramp_name\n",
    "        summary[\"Direction\"] = direction\n",
    "        summary[\"PassGantryID\"] = pass_id\n",
    "        summary[\"UnpassGantryID\"] = unpass_id\n",
    "\n",
    "        # 加入結果\n",
    "        results.append(summary)\n",
    "\n",
    "    # 合併所有結果\n",
    "    final_df = pd.concat(results, ignore_index=True)\n",
    "    return final_df\n",
    "\n",
    "def THI_M06A_step3(final_df):\n",
    "    final_df = final_df.pivot_table(index=['DetectionDate', 'DetectionHour', 'Ramp', 'Direction', 'PassGantryID', 'UnpassGantryID'], \n",
    "                                    columns='VehicleType',\n",
    "                                    values='Count',\n",
    "                                    aggfunc='sum',  # 如果有重複的組合，進行加總\n",
    "                                    fill_value=0     # 填充缺失值為 0\n",
    "                                    ).reset_index()\n",
    "    final_df['PCU'] = final_df[5] * 3 + final_df[31]*1 + final_df[32] *1 + final_df[41] * 1.8 + final_df[42] * 1.8\n",
    "    final_df = final_df.groupby(['DetectionDate',  'DetectionHour', 'Ramp', 'Direction', 'PassGantryID', 'UnpassGantryID']).agg({5:'sum', 31:'sum', 32 : 'sum',  41:'sum', 42 :'sum',  'PCU':'sum'}).reset_index()\n",
    "    final_df = final_df.rename(columns = {\n",
    "        5 : 'Vol_Trail',\n",
    "        31 : 'Vol_Car',\n",
    "        32 : 'Vol_Truck',\n",
    "        41 : 'Vol_TourBus',\n",
    "        42 : 'Vol_BTruck'\n",
    "    })\n",
    "    final_df[\"Ramp&Dir\"] = final_df[\"Ramp\"] + \"(\" + final_df[\"Direction\"] + \")\"\n",
    "    final_df['Volume'] = final_df['Vol_Trail'] + final_df['Vol_Car'] + final_df['Vol_BTruck']+ final_df['Vol_TourBus'] + final_df['Vol_Truck']\n",
    "\n",
    "    final_df = final_df.reindex(columns = ['DetectionDate', 'DetectionHour', 'Ramp&Dir','Ramp', 'Direction', 'PassGantryID', 'UnpassGantryID', 'Vol_Trail', 'Vol_BTruck', 'Vol_TourBus', 'Vol_Car', 'Vol_Truck', 'Volume','PCU'])\n",
    "\n",
    "    return final_df\n",
    "\n",
    "def THI_M06A(df):\n",
    "    df = THI_M06A_step1(df)\n",
    "\n",
    "    # 讀取ramp資料\n",
    "    ramp = pd.read_excel(os.path.join(os.getcwd(),'..', 'Input', 'ETag匝道選擇.xlsx'), sheet_name='Ramp', skiprows=1)\n",
    "    ramp = ramp.iloc[:,:4]\n",
    "    ramp = ramp.sort_values(['Ramp', 'Direction'], ascending=[True, False]).reset_index(drop = True)\n",
    "\n",
    "    outputdf = THI_M06A_step2(df = df , ramp = ramp)\n",
    "    outputdf = THI_M06A_step3(outputdf)\n",
    "    return outputdf\n",
    "\n",
    "\n",
    "def THI_M08A(df, hour = True):\n",
    "    df['TimeStamp'] = pd.to_datetime(df['TimeStamp'])\n",
    "\n",
    "    df['Date'] = df['TimeStamp'].dt.date\n",
    "    df['Hour'] = df['TimeStamp'].dt.hour\n",
    "    if hour == True:\n",
    "        df = df.groupby(['Date', 'Hour', 'GantryO', 'GantryD', 'VehicleType']).size().reset_index(name='Volume')\n",
    "    df = df.groupby(['Date', 'GantryO', 'GantryD','VehicleType']).size().reset_index(name='Volume')\n",
    "    return df \n",
    "\n",
    "def THI_process(df, datatype, weighted = False, hour = True):\n",
    "    if datatype == 'M03A':\n",
    "        df = THI_M03A(df)\n",
    "    elif datatype == 'M05A':\n",
    "        df = THI_M05A(df, weighted = weighted)\n",
    "    elif datatype == 'M06A':\n",
    "        df = THI_M06A(df)\n",
    "    elif datatype == 'M08A':\n",
    "        df = THI_M08A(df, hour = True)\n",
    "    return df\n",
    "\n",
    "# def M03A_Tableau_combined(folder , etag):\n",
    "#     allfiles = findfiles(filefolderpath=folder, filetype='.xlsx')\n",
    "#     combineddf = pd.concat(\n",
    "#         (pd.read_excel(i) for i in allfiles),  # 使用生成器表達式\n",
    "#         ignore_index=True  # 避免重複的索引\n",
    "#     )\n",
    "\n",
    "#     combineddf['Day'] = combineddf[\"Date\"].dt.day_name() #生成星期幾\n",
    "\n",
    "#     combineddf = pd.merge(combineddf,etag[['ETagGantryID', 'RoadName','Start', 'End']].rename(columns = {'ETagGantryID':'GantryID'}) , on = 'GantryID')\n",
    "#     combineddf['RoadSection'] = combineddf['Start'] + '-' + combineddf['End']\n",
    "\n",
    "#     outputfolder = create_folder(os.path.join(folder, '..', '3_TableauData'))\n",
    "#     combineddf.to_csv(os.path.join(outputfolder, 'M03A.csv'), index=False)\n",
    "\n",
    "def M03A_Tableau_combined(folder , etag):\n",
    "    allfiles = findfiles(filefolderpath=folder, filetype='.xlsx')\n",
    "    combineddf = pd.concat(\n",
    "        (pd.read_excel(i) for i in allfiles),  # 使用生成器表達式\n",
    "        ignore_index=True  # 避免重複的索引\n",
    "    )\n",
    "\n",
    "    # 轉換為長格式（long format）\n",
    "    combineddf = combineddf.melt(id_vars=[\"Date\", \"Hour\", \"GantryID\", \"Direction\"], \n",
    "                        value_vars=[\"Vol_Trail\", \"Vol_Car\", \"Vol_Truck\", \"Vol_TourBus\", \"Vol_BTruck\"],\n",
    "                        var_name=\"VehicleType\", \n",
    "                        value_name=\"Volume\")\n",
    "\n",
    "    # 轉換 VehicleType 名稱\n",
    "    vehicle_mapping = {\n",
    "        \"Vol_Trail\": 5,\n",
    "        \"Vol_Car\": 31,\n",
    "        \"Vol_Truck\": 32,\n",
    "        \"Vol_TourBus\": 41,\n",
    "        \"Vol_BTruck\": 42\n",
    "    }\n",
    "\n",
    "    combineddf[\"VehicleType\"] = combineddf[\"VehicleType\"].map(vehicle_mapping)\n",
    "    combineddf[\"VehicleType\"] = combineddf[\"VehicleType\"].astype('int64')\n",
    "\n",
    "\n",
    "    combineddf['Day'] = combineddf[\"Date\"].dt.day_name() #生成星期幾\n",
    "\n",
    "    combineddf = pd.merge(combineddf,etag[['ETagGantryID', 'RoadName','Start', 'End']].rename(columns = {'ETagGantryID':'GantryID'}) , on = 'GantryID')\n",
    "    combineddf['RoadSection'] = combineddf['Start'] + '-' + combineddf['End']\n",
    "\n",
    "    outputfolder = create_folder(os.path.join(folder, '..', '3_TableauData'))\n",
    "    combineddf.to_csv(os.path.join(outputfolder, 'M03A.csv'), index=False)\n",
    "\n",
    "def freeway(datatype, datelist, Tableau = False, etag = None, keep = False):\n",
    "    rawdatafolder, mergefolder, excelfolder = freewaydatafolder(datatype=datatype)\n",
    "    url = \"https://tisvcloud.freeway.gov.tw/history/TDCS/\" + datatype\n",
    "\n",
    "    for date in datelist :\n",
    "        # 1. 下載並解壓縮\n",
    "        dowloadfilefolder = download_and_extract(url = url, datatype = datatype, date = date, downloadfolder = rawdatafolder, keep = False)\n",
    "\n",
    "        # 2. 合併\n",
    "        filelist = findfiles(filefolderpath=dowloadfilefolder, filetype='.csv')\n",
    "        df = combinefile(filelist=filelist, datatype=datatype)\n",
    "        mergeoutputfolder = create_folder(os.path.join(mergefolder, date)) # 建立相同日期的資料夾進行處理\n",
    "        df.to_csv(os.path.join(mergeoutputfolder, f'{date}.csv') , index = False) # 輸出整併過的csv\n",
    "        delete_folders([dowloadfilefolder]) #回頭刪除解壓縮過的資料\n",
    "\n",
    "        # # 3. 處理\n",
    "        df = THI_process(df, datatype=datatype)\n",
    "        df.to_excel(os.path.join(excelfolder, f'{date}.xlsx'), index = False, sheet_name = date)\n",
    "    \n",
    "    if Tableau == True:\n",
    "        if datatype == 'M03A':\n",
    "            M03A_Tableau_combined(folder=excelfolder, etag = etag)\n",
    "\n",
    "    return df\n",
    "\n",
    "# ===== Step 0: 手動需要調整的參數 =====\n",
    "\n",
    "# 調整下載的資料區間\n",
    "# starttime = \"2025-01-24\"\n",
    "# endtime = \"2025-01-24\"\n",
    "# datelist = getdatelist(endtime,starttime) # 下載的時間區間清單\n",
    "datelist = ['20250619', '20250621']\n",
    "\n",
    "# ===== Step 1: 選擇需要執行的程式碼 ====\n",
    "\n",
    "def main():\n",
    "    '''主要會用freeway這個函數進行三個步驟 (1) 下載 (2) 整併當日資料 (3) 處理\n",
    "    請根據需要調整datatype(str)\n",
    "\n",
    "    1. M03A : 主要計算主要路段通過門架的通過量\n",
    "    2. M05A : 計算通過兩個門架間的速率\n",
    "    3. M06A : 計算進出匝道進出的數量 (需事先至 \"/Input/ETag匝道選擇.xlsx\" 進行挑選需要的篩選的進出匝道)\n",
    "    4. M08A : 計算通過兩個門架之間的OD數量\n",
    "    '''\n",
    "\n",
    "    etag = etag_getdf()\n",
    "\n",
    "    # (1) M03A: 兩行程式碼擇一\n",
    "    freeway(datatype = 'M03A', datelist = datelist)\n",
    "    # freeway(datatype = 'M03A', datelist = datelist, keep=False, Tableau = True, etag = etag)  #如果有要轉tableau 的格式則要用這個程式碼\n",
    "\n",
    "    # (2) M05A: \n",
    "    # freeway(datatype = 'M05A', datelist = datelist) \n",
    "\n",
    "    # # (3) M06A: 至2_excel 的部分為匝道進出資料，因次要補主縣通過量\n",
    "    # freeway(datatype = 'M06A', datelist = datelist)\n",
    "    # try:\n",
    "    #     filefolderpath = os.path.abspath(os.path.join(os.getcwd(),'..','Output', 'M06A', '1_merge'))\n",
    "    #     filelist = findfiles(filefolderpath=filefolderpath)\n",
    "    #     for i in range(len(filelist)): \n",
    "    #         filename = os.path.basename(filelist[i])\n",
    "    #         basename_without_ext = os.path.splitext(filename)[0]  # 去掉副檔名\n",
    "            \n",
    "    #         df = pd.read_csv(filelist[i])\n",
    "    #         df = THI_M06A_step1(df)\n",
    "    #         df = df.groupby(['DetectionDate', 'DetectionHour', 'GantryID', 'VehicleType'])[\"index\"].nunique().reset_index(name=\"Volume\")\n",
    "    #         df.to_excel(os.path.join('M06A', '2_excel', f'{basename_without_ext}_主線通過量.xlsx'))\n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "    # (4) M08A:\n",
    "    # freeway(datatype = 'M08A', datelist = datelist)\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
